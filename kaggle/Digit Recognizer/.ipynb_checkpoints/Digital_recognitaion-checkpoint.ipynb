{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#author:vincent\n",
    "#所需库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import copy\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import csv\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toInt(array):\n",
    "    array=np.mat(array)\n",
    "    m,n=np.shape(array)\n",
    "    newArray=np.zeros((m,n))\n",
    "    for i in xrange(m):\n",
    "            for j in xrange(n):\n",
    "                newArray[i,j]=int(array[i,j])\n",
    "    return newArray\n",
    "def normalize(array):\n",
    "    m,n=np.shape(array)\n",
    "    for i in xrange(m):\n",
    "        for j in xrange(n):\n",
    "            if array[i][j]!=0:\n",
    "                array[i][j]=1\n",
    "    return array\n",
    "#从csv中载入训练集和测试集\n",
    "def LoadTrainData(filepath):\n",
    "    l=[]\n",
    "    with open(filepath) as f:\n",
    "        lines=csv.reader(f)\n",
    "        for line in lines:\n",
    "            l.append(line)\n",
    "    l.remove(l[0])\n",
    "    i=np.array(l)\n",
    "    lable=i[:,0]\n",
    "    data=i[:,1:]\n",
    "    return normalize(toInt(data)),toInt(lable)\n",
    "def LoadTestData(filepath):\n",
    "    l=[]\n",
    "    with open(filepath) as f:\n",
    "        lines=csv.reader(f)\n",
    "        for line in lines:\n",
    "            l.append(line)\n",
    "    l.remove(l[0])\n",
    "    data=np.array(l)\n",
    "    return normalize(toInt(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#建立数据集：其中包括训练数据和验证数据\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,root,transform=None,phase=None,ratio=0.7):\n",
    "        self.root=root\n",
    "        numbers,labels=LoadTrainData(self.root)\n",
    "        labels=labels[0]\n",
    "        if phase=='train':\n",
    "            self.numbers=numbers[:int(len(numbers)*ratio)]\n",
    "            self.label=labels[:int(len(numbers)*ratio)]\n",
    "        elif phase=='val':\n",
    "            self.numbers=numbers[int(len(numbers)*ratio)+1:]\n",
    "            self.label=labels[int(len(numbers)*ratio)+1:]\n",
    "        else:\n",
    "            raise(RuntimeError(\"phase is wrong\"))\n",
    "\n",
    "        self.phase=phase\n",
    "        self.transform=transform\n",
    "    def __getitem__(self,idx):\n",
    "        number=self.numbers[idx]\n",
    "        label=self.label[idx]\n",
    "        #原数据为（1,784）\n",
    "        number=number.reshape((28,28))\n",
    "        number=np.expand_dims(number,0)\n",
    "        number=torch.from_numpy(number)\n",
    "        number=number.type(torch.FloatTensor)\n",
    "        return number,label\n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (256 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#训练所用网络模型：\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*4*4, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "model = Net().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_model(model, criterion, optimizer, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = optimizer\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                labels=labels.type(torch.LongTensor)\n",
    "                #print(type(labels))\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                #print type(outputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds== labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects) / float(dset_sizes[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model\n",
    "\n",
    "def optim_scheduler_ft(model, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
    "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#载入数据集\n",
    "train_path='./train.csv'\n",
    "dset={x:Dataset(train_path,phase=x) for x in ['train','val']}\n",
    "dset_loaders={x:torch.utils.data.DataLoader(dset[x],batch_size=8,shuffle=True,num_workers=4) for x in ['train','val']}\n",
    "dset_sizes = {x: len(dset[x]) for x in ['train', 'val']}\n",
    "dset_classes =dset['val'].label\n",
    "print (dset_sizes)\n",
    "print (len(dset_classes))\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.1024 Acc: 0.7225\n",
      "val Loss: 0.0264 Acc: 0.9321\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0208 Acc: 0.9471\n",
      "val Loss: 0.0168 Acc: 0.9561\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0148 Acc: 0.9615\n",
      "val Loss: 0.0139 Acc: 0.9643\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0121 Acc: 0.9690\n",
      "val Loss: 0.0120 Acc: 0.9687\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9747\n",
      "val Loss: 0.0105 Acc: 0.9746\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0086 Acc: 0.9776\n",
      "val Loss: 0.0106 Acc: 0.9728\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0074 Acc: 0.9806\n",
      "val Loss: 0.0097 Acc: 0.9763\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0066 Acc: 0.9832\n",
      "val Loss: 0.0113 Acc: 0.9737\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9843\n",
      "val Loss: 0.0097 Acc: 0.9754\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0052 Acc: 0.9858\n",
      "val Loss: 0.0090 Acc: 0.9772\n",
      "Training complete in 3m 17s\n",
      "Best val Acc: 0.977222\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcc/anaconda2/lib/python2.7/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#保存训练好的模型\n",
    "torch.save(model, 'digital_model_epoch10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#保存测试结果，得到的是lable数组\n",
    "def saveResult(result):\n",
    "    with open('result.csv','wb') as myFile:    \n",
    "        myWriter=csv.writer(myFile)\n",
    "        for i in result:\n",
    "            tmp=[]\n",
    "            tmp.append(i)\n",
    "            myWriter.writerow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把结果转成提交格式\n",
    "def result2sub(sub_path):\n",
    "    with open('result.csv','rb') as f:\n",
    "        lines=csv.reader(f)\n",
    "        a=[]\n",
    "        count=1\n",
    "        a.append(['ImageId','Label'])\n",
    "        for line in lines:\n",
    "            a.append([count,int(float(line[0]))])\n",
    "            count=count+1\n",
    "    with open(sub_path,'wb') as f:\n",
    "        writer=csv.writer(f)\n",
    "        for i in a:\n",
    "            temp=[]\n",
    "            temp.append(i[0])\n",
    "            temp.append(i[1])\n",
    "            writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试结果\n",
    "def Test(model,test_nums):\n",
    "    result=[]\n",
    "    for i in range(len(test_nums)):\n",
    "        number=test_nums[i]\n",
    "        number=number.reshape((28,28))\n",
    "        number=np.expand_dims(number,0)\n",
    "        number=np.expand_dims(number,0)\n",
    "        number=torch.from_numpy(number)\n",
    "        inputs=number.type(torch.FloatTensor)\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        outputs=model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        preds=int(preds.cpu().numpy())\n",
    "        result.append(preds)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试：\n",
    "test_path='./test.csv'\n",
    "test_nums=LoadTestData(test_path)\n",
    "result=Test(model,test_nums)\n",
    "saveResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#转成提交格式\n",
    "sub_path='./submission_lenet2.csv'\n",
    "result2sub(sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
