{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy+Zhang Liangjun\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "#文件路径\n",
    "#filepath = '/home/gcc/dataset/test-xyz_depth.mat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy /home/gcc/dataset/test done\n",
      "copy /home/gcc/dataset/test/test1 done\n",
      "copy /home/gcc/dataset/test/test2 done\n",
      "copy /home/gcc/dataset/test/test1/test11 done\n",
      "copy /home/gcc/dataset/test/test1/test12 done\n"
     ]
    }
   ],
   "source": [
    "#input:mat file\n",
    "#output: tensor\n",
    "def mat_read(filepath):\n",
    "    dataFile = filepath\n",
    "    data = scio.loadmat(dataFile)\n",
    "    #读取mat里的depth数据\n",
    "    depth = data['depth']\n",
    "    #############把nan替换为 0 or 其他数（还没有考虑好）\n",
    "    ##TODO\n",
    "    where_are_nan = np.isnan(depth)\n",
    "    depth[where_are_nan] = 0\n",
    "    #create tensor from numpy.ndarray\n",
    "    depth=torch.from_numpy(depth)\n",
    "    return depth\n",
    "\n",
    "#把数据文件分成训练集和测试集\n",
    "def generate_datasets(data_dir, dst_dir, train_ratio=0.6):\n",
    "    train_dir = os.path.join(dst_dir,'train')\n",
    "    val_dir = os.path.join(dst_dir,'val')\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.mkdir(dst_dir)\n",
    "        os.mkdir(train_dir)\n",
    "        os.mkdir(val_dir)\n",
    "    for root, dirnames, _ in os.walk(data_dir):\n",
    "        for dirname in dirnames:\n",
    "            subdirname_train = os.path.join(train_dir, dirname)\n",
    "            subdirname_val = os.path.join(val_dir, dirname)\n",
    "            if not os.path.exists(subdirname_train):\n",
    "                os.mkdir(subdirname_train)\n",
    "            if not os.path.exists(subdirname_val):\n",
    "                os.mkdir(subdirname_val)                                        \n",
    "            dname = os.path.join(root, dirname)\n",
    "            names = glob.glob(dname+r'/*.mat')  \n",
    "            random.shuffle(names)\n",
    "            names_len = len(names)\n",
    "            train_names = names[:int(names_len*train_ratio)]\n",
    "            val_names = names[int(names_len*train_ratio)+1:]\n",
    "            for f in train_names:\n",
    "                fname = os.path.split(f)[-1]\n",
    "                train_dname = os.path.join(subdirname_train, fname)\n",
    "                shutil.copyfile(f, train_dname)\n",
    "            for f in val_names:\n",
    "                fname = os.path.split(f)[-1]\n",
    "                val_dname = os.path.join(subdirname_val, fname)\n",
    "                shutil.copyfile(f, val_dname)\n",
    "            print ('copy {} done'.format(dname))\n",
    "        \n",
    "#data_dir = '/home/gcc/dataset'\n",
    "#dst_dir = '/home/gcc/viewpoint'\n",
    "#generate_datasets(data_dir, dst_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXTENSIONS = ['.mat']\n",
    "def is_mat_file(filename):\n",
    "    return any(filename.endwith(extension) for extension in EXTENSIONS)\n",
    "\n",
    "#类名\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir,d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]:i for i in range(len(classes))}\n",
    "    return classes,class_to_idx\n",
    "\n",
    "#input: dir+train(or val)+class\n",
    "#output: 数据文件的集合\n",
    "def make_dataset(dir,phase,class_to_idx):\n",
    "    datas = []\n",
    "    dir = os.path.join(dir,phase)\n",
    "    for target in os.listdir(dir):\n",
    "        d = os.path.join(dir,target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        \n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in fnames:\n",
    "                if is_mat_file(fname):\n",
    "                    path = os.path.join(root,fname)\n",
    "                    item = (path,class_to_idx[target])\n",
    "                    datas.append(item)\n",
    "    return datas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ViewpointDataset(data.Dataset):\n",
    "    def __init__(self, root, transform = None, phase = None):\n",
    "        dir = os.path.join(root, phase)\n",
    "        classes, class_to_idx = find_classes(dir)\n",
    "        datas = make_dataset(root,phase, class_to_idx)\n",
    "        if len(datas) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported extensions are: \" + \",\".join(EXTENSIONS)))\n",
    "        self.root = root\n",
    "        self.datas = datas\n",
    "        self.phase = phase\n",
    "        self.classes = classes\n",
    "        #todo\n",
    "        self.width = 480\n",
    "        self.height = 640\n",
    "        self.suffix = '.mat'\n",
    "        self.transform = transform\n",
    "        \n",
    "    #深度矩阵转成tensor  \n",
    "    def __getitem__(self, idx):\n",
    "        mat_path, label = self.datas[idx]\n",
    "        #preprocess\n",
    "        depth = mat_read(mat_path)            \n",
    "        \n",
    "        #numpy转成tensor\n",
    "        depth_tensor = torch.from_numpy(depth)\n",
    "      \n",
    "        return depth_tensor, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 images in subfolders of: /home/gcc/viewpoint\nSupported extensions are: .mat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-10a5afff5749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mViewpointDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdset_loaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdset_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdset_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-10a5afff5749>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((x,))\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mViewpointDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdset_loaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdset_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdset_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-34c84c40ce36>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, phase)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n\u001b[0;32m----> 8\u001b[0;31m                                \"Supported extensions are: \" + \",\".join(EXTENSIONS)))\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found 0 images in subfolders of: /home/gcc/viewpoint\nSupported extensions are: .mat"
     ]
    }
   ],
   "source": [
    "#建立数据集\n",
    "dsets = {x: ViewpointDataset(dst_dir,phase=x) for x in ['train', 'val']}\n",
    "dset_loaders = {x:torch.utils.data.DataLoader(dsets[x],batch_size=16,shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "dset_classes = dsets['val'].classes\n",
    "print(dset_sizes)\n",
    "print(len(dset_classes))\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置梯度更新方式\n",
    "def optim_scheduler_ft(model, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
    "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "model = models.resnet34(pretrained=True)\n",
    "#model还可以是各种卷积网络结构，到时候调整\n",
    "#model = torch.load(\"model_epoch25.pkl\")\n",
    "print (model)\n",
    "num_ftrs = model.fc.in_features\n",
    "classes = len(dset_classes)\n",
    "model.fc = nn.Linear(num_ftrs, classes)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##定义模型如何训练\n",
    "def train_model(model, criterion, optim_scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = optim_scheduler(model, epoch)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds== labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects) / float(dset_sizes[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练\n",
    "model = train_model(model, criterion, optim_scheduler_ft, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##在测试集中测试\n",
    "def visualize_model(model, num_images=5):\n",
    "    for i, data in enumerate(dset_loaders['val']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        preds = preds.cpu().numpy()\n",
    "        print dset_classes[preds[0][0]]\n",
    "\n",
    "        if i == num_images - 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#单个图测试\n",
    "def predict_depth_mat(model,dep_path):\n",
    "    inputs = mat_read(dep_path)\n",
    "    if use_gpu:\n",
    "        inputs = Variable(inputs.cuda())\n",
    "    outputs = model(inputs)\n",
    "    _,preds = torch.max(outputs.data, 1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    print dset_classes[preds[0][0]]\n",
    "#等到知道真实深度图是什么类型的数据和怎么处理后再写\n",
    "def predict_depthmap(model,image):\n",
    "    pass\n",
    "filename = 'mat文件地址'\n",
    "predict_depth_mat(model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "torch.save(model, 'model_epoch50.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
